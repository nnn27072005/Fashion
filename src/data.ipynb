{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, root, ann_file, feature_extractor, train=False, num_attributes=294):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): Đường dẫn thư mục ảnh.\n",
    "            ann_file (str): Đường dẫn file JSON annotation.\n",
    "            feature_extractor: YolosImageProcessor từ HuggingFace.\n",
    "            train (bool): Nếu True sẽ áp dụng Augmentation.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.coco = COCO(os.path.join(root, ann_file))\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.num_attributes = num_attributes\n",
    "        self.train = train\n",
    "        \n",
    "        # Khởi tạo Augmentation pipeline\n",
    "        self.transforms = self.get_transforms(train=train)\n",
    "\n",
    "    def get_transforms(self, train=False):\n",
    "        \"\"\"\n",
    "        Cấu hình Augmentation - Chìa khóa xử lý Small Objects & Imbalance\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            return A.Compose([\n",
    "                # --- CHIẾN LƯỢC CHO VẬT THỂ NHỎ (SMALL OBJECTS) ---\n",
    "                # RandomCrop giúp model \"nhìn gần\" hơn vào chi tiết (nhẫn, đồng hồ)\n",
    "                # Thay vì resize ảnh 3000px xuống 800px (mất chi tiết), ta cắt lấy vùng 800x800\n",
    "                A.OneOf([\n",
    "                    A.RandomCrop(width=800, height=800, p=0.5),\n",
    "                    A.RandomResizedCrop(width=800, height=800, scale=(0.5, 1.0), p=0.5),\n",
    "                ], p=0.6),\n",
    "\n",
    "                # --- CHIẾN LƯỢC TĂNG ĐA DẠNG DỮ LIỆU ---\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.3),\n",
    "                \n",
    "                # Biến đổi màu sắc để model không phụ thuộc vào ánh sáng\n",
    "                A.RandomBrightnessContrast(p=0.2),\n",
    "                A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.2),\n",
    "                \n",
    "                # Đảm bảo ảnh đầu ra không quá lớn gây tràn RAM\n",
    "                A.LongestMaxSize(max_size=1333), \n",
    "                A.PadIfNeeded(min_height=800, min_width=800, border_mode=cv2.BORDER_CONSTANT, value=[124, 116, 104])\n",
    "            ], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids', 'attribute_ids'], min_visibility=0.3))\n",
    "        else:\n",
    "            # Với tập Val/Test, chỉ Resize cơ bản\n",
    "            return A.Compose([\n",
    "                A.LongestMaxSize(max_size=1333),\n",
    "                A.PadIfNeeded(min_height=800, min_width=800, border_mode=cv2.BORDER_CONSTANT, value=[124, 116, 104])\n",
    "            ], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids', 'attribute_ids']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        coco_target = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # 1. Load ảnh\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        img_path = os.path.join(self.root, path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Albumentations dùng numpy RGB\n",
    "\n",
    "        # 2. Parse Annotations ban đầu\n",
    "        boxes = []\n",
    "        category_ids = []\n",
    "        attribute_ids_list = [] # List các list attributes\n",
    "        area = []\n",
    "        iscrowd = []\n",
    "\n",
    "        for ann in coco_target:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            if w < 1 or h < 1: continue\n",
    "            \n",
    "            boxes.append([x, y, w, h]) # COCO format cho Albumentations\n",
    "            category_ids.append(ann['category_id'])\n",
    "            area.append(ann['area'])\n",
    "            iscrowd.append(ann['iscrowd'])\n",
    "            \n",
    "            # Giữ lại attribute_ids để transform theo box\n",
    "            attrs = ann.get('attribute_ids', [])\n",
    "            attribute_ids_list.append(attrs)\n",
    "\n",
    "        # 3. Áp dụng Augmentation (Crop, Flip, etc.)\n",
    "        if self.transforms:\n",
    "            try:\n",
    "                transformed = self.transforms(\n",
    "                    image=image, \n",
    "                    bboxes=boxes, \n",
    "                    category_ids=category_ids,\n",
    "                    attribute_ids=attribute_ids_list\n",
    "                )\n",
    "                image = transformed['image']\n",
    "                boxes = transformed['bboxes']\n",
    "                category_ids = transformed['category_ids']\n",
    "                attribute_ids_list = transformed['attribute_ids']\n",
    "            except ValueError:\n",
    "                # Fallback nếu augmentation lỗi (thường do box nằm ngoài ảnh sau crop)\n",
    "                pass\n",
    "\n",
    "        # 4. Format lại dữ liệu cho YOLOS Processor\n",
    "        # YOLOS yêu cầu boxes dạng [x_min, y_min, x_max, y_max]\n",
    "        final_boxes = []\n",
    "        final_attributes = []\n",
    "        \n",
    "        for i, box in enumerate(boxes):\n",
    "            x, y, w, h = box\n",
    "            final_boxes.append([x, y, x + w, y + h])\n",
    "            \n",
    "            # Xử lý Multi-hot vector cho Attributes\n",
    "            attr_vec = torch.zeros(self.num_attributes, dtype=torch.float32)\n",
    "            valid_ids = [aid for aid in attribute_ids_list[i] if aid < self.num_attributes]\n",
    "            if valid_ids:\n",
    "                attr_vec[valid_ids] = 1.0\n",
    "            final_attributes.append(attr_vec)\n",
    "\n",
    "        # 5. Đóng gói Target\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(final_boxes, dtype=torch.float32)\n",
    "        target[\"class_labels\"] = torch.as_tensor(category_ids, dtype=torch.long)\n",
    "        target[\"image_id\"] = torch.tensor([img_id])\n",
    "        \n",
    "        # Xử lý trường hợp ảnh không còn box nào sau khi Crop\n",
    "        if len(final_attributes) > 0:\n",
    "            target[\"attribute_labels\"] = torch.stack(final_attributes)\n",
    "            target[\"area\"] = torch.as_tensor(area[:len(final_boxes)], dtype=torch.float32) # Area có thể sai lệch sau crop nhưng tạm chấp nhận\n",
    "            target[\"iscrowd\"] = torch.as_tensor(iscrowd[:len(final_boxes)], dtype=torch.int64)\n",
    "        else:\n",
    "             # Tạo tensor rỗng nếu mất hết object\n",
    "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            target[\"class_labels\"] = torch.zeros((0,), dtype=torch.long)\n",
    "            target[\"attribute_labels\"] = torch.zeros((0, self.num_attributes), dtype=torch.float32)\n",
    "            target[\"area\"] = torch.zeros((0,), dtype=torch.float32)\n",
    "            target[\"iscrowd\"] = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        # 6. Feature Extractor (Normalization & Formatting cuois cùng)\n",
    "        # Lưu ý: Ta truyền ảnh đã augment (numpy) vào, processor sẽ convert sang Tensor\n",
    "        encoding = self.feature_extractor(\n",
    "            images=image, \n",
    "            annotations=target, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def get_weighted_sampler(self):\n",
    "        \"\"\"\n",
    "        Tính toán trọng số lấy mẫu (Sampling Weights) để xử lý Imbalanced Data.\n",
    "        Logic: Ảnh nào chứa class hiếm (VD: Nhẫn) sẽ có trọng số cao hơn.\n",
    "        \"\"\"\n",
    "        print(\"Đang tính toán Class Weights để cân bằng dữ liệu...\")\n",
    "        \n",
    "        # 1. Đếm tần suất xuất hiện của từng Class\n",
    "        class_counts = {}\n",
    "        img_class_map = {} # img_id -> list of classes\n",
    "        \n",
    "        for img_id in self.ids:\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "            classes = [ann['category_id'] for ann in anns]\n",
    "            img_class_map[img_id] = classes\n",
    "            \n",
    "            for c in classes:\n",
    "                class_counts[c] = class_counts.get(c, 0) + 1\n",
    "        \n",
    "        # 2. Tính Weight cho từng Class (Inverse Frequency)\n",
    "        # Weight = Tổng số mẫu / Số mẫu của class đó\n",
    "        total_samples = sum(class_counts.values())\n",
    "        class_weights = {c: total_samples / (cnt + 1e-6) for c, cnt in class_counts.items()}\n",
    "        \n",
    "        # 3. Gán Weight cho từng Ảnh\n",
    "        # Weight của ảnh = Weight lớn nhất của class có trong ảnh đó\n",
    "        # (Ví dụ: Ảnh có Áo (common) và Nhẫn (rare) -> Lấy weight của Nhẫn)\n",
    "        sample_weights = []\n",
    "        for img_id in self.ids:\n",
    "            classes = img_class_map.get(img_id, [])\n",
    "            if not classes:\n",
    "                weight = 0.0 # Bỏ qua ảnh không có object\n",
    "            else:\n",
    "                # Lấy max weight (ưu tiên class hiếm nhất trong ảnh)\n",
    "                weight = max([class_weights.get(c, 0) for c in classes])\n",
    "            sample_weights.append(weight)\n",
    "            \n",
    "        sample_weights = torch.as_tensor(sample_weights, dtype=torch.double)\n",
    "        \n",
    "        # Trả về Sampler\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        return sampler"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
